{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta, time\n",
    "import holidays\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTzRows(data, dtList): \n",
    "    \"\"\"remove rows of datetimes that do not exist due to tz changes.\"\"\"\n",
    "    for d in dtList:\n",
    "        if d in data.index:\n",
    "            data.drop(d, inplace=True)\n",
    "            print(str(d) + \" dropped.\")  \n",
    "    return data\n",
    "def newIndex(start, end, delta):\n",
    "    \"\"\"create a new index for reindexing.\"\"\"\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr\n",
    "        curr += delta\n",
    "        \n",
    "def prepData(data, delta=60):\n",
    "    # some zones have missing values\n",
    "    # that are supposed to be zero.\n",
    "    data.fillna(0, axis=1, inplace=True)\n",
    "    # drop the hour between 2 and 3 \n",
    "    # when US time goes so summer time\n",
    "    data = removeTzRows(data, tzDates)\n",
    "    # drop duplicate index rows\n",
    "    duplicateNumber = data.index.duplicated().astype(int).sum()\n",
    "    data = data.loc[~data.index.duplicated(keep='first')]\n",
    "    print(str(duplicateNumber) + \" duplicates found and removed.\")\n",
    "    # create new index with 30 minute time interval\n",
    "    reindx = list()\n",
    "    for result in newIndex(startDt, endDt, timedelta(minutes=delta)):\n",
    "        reindx.append(result)\n",
    "    # reindex so there are no missing datetimes\n",
    "    data = data.reindex(reindx)\n",
    "    # fill missing values with their previous one\n",
    "    data.fillna(method=\"ffill\", inplace=True)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDt = datetime(2017, 1, 1, 0, 0)\n",
    "endDt = datetime(2020, 1, 1, 0, 0)\n",
    "# datetimes that should not exist due to tz changes\n",
    "tzDates = [datetime(2017,3,12,2,0), datetime(2017,3,12,2,30),\n",
    "            datetime(2018,3,11,2,0), datetime(2018,3,11,2,30),\n",
    "            datetime(2019,3,10,2,0), datetime(2019,3,10,2,30)\n",
    "           ]\n",
    "usHolidays = holidays.UnitedStates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load zone details\n",
    "zones = pd.read_csv('taxi_data/taxiZoneLookup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* aggregates trips for every dt for each zone\n",
    "* time-series format\n",
    "* used to explore trips more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggr_data(years):\n",
    "    check = 1\n",
    "    for year in years:\n",
    "        for month in range(1,13):\n",
    "            path = \"taxi_data/yellow_tripdata_{}-{}{}\".format(year, f\"{month:02d}\", \".csv\")\n",
    "            df = pd.read_csv(path, \n",
    "                             parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"], \n",
    "                             low_memory=False)\n",
    "            \n",
    "            df = df[[\"tpep_pickup_datetime\", \n",
    "                     \"tpep_dropoff_datetime\", \n",
    "                     \"trip_distance\", \n",
    "                     \"passenger_count\", \n",
    "                     \"PULocationID\", \n",
    "                     \"DOLocationID\"]]\n",
    "            \n",
    "            #only trips shorter than 100 miles\n",
    "            df = df[df.trip_distance < 100]\n",
    "            #only trips with at least 1 passenger\n",
    "            df = df[df.passenger_count != 0]\n",
    "            #calculate trip duration\n",
    "            df[\"trip_duration\"] = df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]\n",
    "            #only trips longer than 1 minute and shorter than 3 hours\n",
    "            df = df[(df.trip_duration > timedelta(minutes=1)) & (df.trip_duration < timedelta(hours=3))]\n",
    "            \n",
    "            #merge borough from the zones dataframe\n",
    "            #so trips can be filtered for Manhattan, Queens and Brooklyn only\n",
    "            df.rename(columns={\"PULocationID\": \"LocationID\"}, inplace=True)\n",
    "            df = pd.merge(df, zones[[\"LocationID\", \"Borough\"]], on=\"LocationID\", how=\"left\")\n",
    "            df.rename(columns={\"LocationID\": \"PULocationID\", \"Borough\": \"PUBorough\", \"Zone\": \"PUZone\"}, inplace=True)\n",
    "            df.rename(columns={\"DOLocationID\": \"LocationID\"}, inplace=True)\n",
    "            df = pd.merge(df, zones[[\"LocationID\", \"Borough\"]], on=\"LocationID\", how=\"left\")\n",
    "            df.rename(columns={\"LocationID\": \"DOLocationID\", \"Borough\": \"DOBorough\", \"Zone\": \"DOZone\"}, inplace=True)\n",
    "            \n",
    "            #only include trips from and to Manhattan, Queens or Brooklyn\n",
    "            boroughs = [\"Manhattan\", \"Queens\", \"Brooklyn\"]\n",
    "            df = df[(df.PUBorough.isin(boroughs)) & (df.DOBorough.isin(boroughs))]\n",
    "            \n",
    "            #drop everything except datetime information and pickup location\n",
    "            df = df[[\"tpep_pickup_datetime\", \"PULocationID\"]]\n",
    "            \n",
    "            #only include trips that fill in the current year and month\n",
    "            if month != 12:\n",
    "                df = df[(df.tpep_pickup_datetime >= datetime(year,month,1)) & (df.tpep_pickup_datetime < datetime(year,month+1,1))]\n",
    "            else:\n",
    "                df = df[(df.tpep_pickup_datetime >= datetime(year,month,1)) & (df.tpep_pickup_datetime < datetime(year+1,1,1))]\n",
    "            \n",
    "            #round pickup datetime to full hours\n",
    "            df[\"tpep_pickup_datetime\"] = df[\"tpep_pickup_datetime\"].apply(lambda x: x - timedelta(minutes=x.minute % 60, seconds=x.second))    \n",
    "            #create a dummy for each zone\n",
    "            df = df[[\"tpep_pickup_datetime\"]].join(pd.get_dummies(df.PULocationID))\n",
    "            #aggregate trips for every zone at every pickup datetime\n",
    "            df = df.groupby(\"tpep_pickup_datetime\").sum()    \n",
    "            \n",
    "            #aggregate data unless it's the first data set (here 1/2017)\n",
    "            if check == 0:\n",
    "                final = pd.concat([final, df], sort=False)\n",
    "            else:\n",
    "                final = df\n",
    "                check = 0\n",
    "                \n",
    "            print(str(year) + \"-\" + str(month))\n",
    "            \n",
    "    return final\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-1\n",
      "2019-2\n",
      "2019-3\n",
      "2019-4\n",
      "2019-5\n",
      "2019-6\n",
      "2019-7\n",
      "2019-8\n",
      "2019-9\n",
      "2019-10\n",
      "2019-11\n",
      "2019-12\n"
     ]
    }
   ],
   "source": [
    "#years = [2017,2018,2019]\n",
    "years = [2019]\n",
    "df1 = get_aggr_data(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"taxi_data/aggr_taxi_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv(\"taxi_data/aggr_taxi_data.csv\", index_col=[\"pickup_dt\"], parse_dates=[\"pickup_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-12 02:00:00 dropped.\n",
      "2018-03-11 02:00:00 dropped.\n",
      "0 duplicates found and removed.\n"
     ]
    }
   ],
   "source": [
    "#remove duplicates or dts that do not exist due to summertime/wintertime shifts\n",
    "df1 = prepData(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv(\"taxi_data/aggr_taxi_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* raw data which will be the base for predictions later\n",
    "* data is accumulated such that every dt has an aggregated number of trips for each zone\n",
    "* no time-series format, but all zones can be included in one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(years):\n",
    "    check = 1\n",
    "    for year in years:\n",
    "        #print(year)\n",
    "        for month in range(1,13):\n",
    "            date_str = str(year)+\"-\"+str(month)\n",
    "            #print(date_str)\n",
    "            \n",
    "            path = \"taxi_data/yellow_tripdata_{}-{}{}\".format(year, f\"{month:02d}\", \".csv\")\n",
    "            df = pd.read_csv(path, \n",
    "                             parse_dates=[\"tpep_pickup_datetime\", \n",
    "                                          \"tpep_dropoff_datetime\"], \n",
    "                             #index_col=[\"tpep_pickup_datetime\"], \n",
    "                             #low_memory=False\n",
    "                            )\n",
    "                     \n",
    "            start = datetime(year,month,1)\n",
    "            if month != 12:\n",
    "                end = datetime(year,month+1,1)\n",
    "            else:\n",
    "                end = datetime(year+1,1,1)\n",
    "            df = df[(df.tpep_pickup_datetime>=start) & (df.tpep_pickup_datetime<end)]\n",
    "            df = df[[\"tpep_pickup_datetime\",\n",
    "                     \"tpep_dropoff_datetime\",\n",
    "                     \"trip_distance\", \n",
    "                     \"passenger_count\",\n",
    "                     \"PULocationID\",\n",
    "                     \"DOLocationID\"]]\n",
    "            \n",
    "            df = df[df.trip_distance < 100]\n",
    "            df = df[df.passenger_count != 0]\n",
    "            df[\"trip_duration\"] = df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]\n",
    "            df = df[(df.trip_duration > timedelta(minutes=1)) & (df.trip_duration < timedelta(hours=3))]\n",
    "            \n",
    "            #merge borough from the zones dataframe\n",
    "            #so trips can be filtered for Manhattan, Queens and Brooklyn only\n",
    "            df.rename(columns={\"PULocationID\": \"LocationID\"}, inplace=True)\n",
    "            df = pd.merge(df, zones[[\"LocationID\", \"Borough\"]], on=\"LocationID\", how=\"left\")\n",
    "            df.rename(columns={\"LocationID\": \"PULocationID\", \n",
    "                               \"Borough\": \"PUBorough\", \n",
    "                               \"Zone\": \"PUZone\"}, \n",
    "                      inplace=True)\n",
    "            \n",
    "            df.rename(columns={\"DOLocationID\": \"LocationID\"}, inplace=True)\n",
    "            df = pd.merge(df, zones[[\"LocationID\", \"Borough\"]], on=\"LocationID\", how=\"left\")\n",
    "            df.rename(columns={\"LocationID\": \"DOLocationID\", \n",
    "                               \"Borough\": \"DOBorough\", \n",
    "                               \"Zone\": \"DOZone\"}, \n",
    "                      inplace=True)\n",
    "            \n",
    "            #only include trips from and to Manhattan, Queens or Brooklyn\n",
    "            boroughs = [\"Manhattan\", \"Queens\", \"Brooklyn\"]\n",
    "            df = df[(df.PUBorough.isin(boroughs)) & (df.DOBorough.isin(boroughs))]\n",
    "            \n",
    "            df = df[[\"tpep_pickup_datetime\", \"PULocationID\"]]\n",
    "            df[\"year\"] = df[\"tpep_pickup_datetime\"].apply(lambda x: x.year)\n",
    "            df[\"month\"] = df[\"tpep_pickup_datetime\"].apply(lambda x: x.month)\n",
    "            df[\"day\"] = df[\"tpep_pickup_datetime\"].apply(lambda x: x.day)\n",
    "            df[\"hour\"] = df[\"tpep_pickup_datetime\"].apply(lambda x: x.hour)\n",
    "            #df[\"wday\"] = df[\"tpep_pickup_datetime\"].apply(lambda x: x.weekday())\n",
    "            df = df.drop(\"tpep_pickup_datetime\", axis=1)\n",
    "            df[\"rides\"] = 0\n",
    "            df = df.groupby([\"PULocationID\", \"year\", \"month\", \"day\", \"hour\"]).agg(\"count\")\n",
    "            df.reset_index(inplace=True)  \n",
    "            if check == 0:\n",
    "                final = pd.concat([final, df], sort=False)\n",
    "            else:\n",
    "                final = df\n",
    "                check = 0\n",
    "            print(str(year) + \"-\" + str(month) + \" done!\")\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = get_data(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53961</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53962</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53963</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53964</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53965</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53966</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53967</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53968</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53969</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53970</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53971</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53972</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53973</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53974</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53975</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53976</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53977</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53978</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53979</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53980</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53981</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53982</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53983</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53984</th>\n",
       "      <td>161</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PULocationID  year  month  day  hour  rides\n",
       "53961           161  2019     12   17     0    282\n",
       "53962           161  2019     12   17     1    103\n",
       "53963           161  2019     12   17     2     49\n",
       "53964           161  2019     12   17     3     26\n",
       "53965           161  2019     12   17     4     20\n",
       "53966           161  2019     12   17     5     41\n",
       "53967           161  2019     12   17     6    110\n",
       "53968           161  2019     12   17     7    286\n",
       "53969           161  2019     12   17     8    411\n",
       "53970           161  2019     12   17     9    461\n",
       "53971           161  2019     12   17    10    490\n",
       "53972           161  2019     12   17    11    607\n",
       "53973           161  2019     12   17    12    580\n",
       "53974           161  2019     12   17    13    654\n",
       "53975           161  2019     12   17    14    654\n",
       "53976           161  2019     12   17    15    618\n",
       "53977           161  2019     12   17    16    528\n",
       "53978           161  2019     12   17    17    466\n",
       "53979           161  2019     12   17    18    653\n",
       "53980           161  2019     12   17    19    716\n",
       "53981           161  2019     12   17    20    941\n",
       "53982           161  2019     12   17    21    881\n",
       "53983           161  2019     12   17    22    829\n",
       "53984           161  2019     12   17    23    668"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[(df2.PULocationID==161) & (df2.year==2019) & (df2.month==12) & (df2.day==17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"taxi_data/taxi_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* adjust data from UTC to NYC time (including daylist saving time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWeatherData(path, tarTimezone=\"US/Eastern\", dateFormat=\"%Y-%m-%d %H:%M\"):\n",
    "    \"\"\"Read weather data, transform datetime to target timezone, set as index.\n",
    "    Keyword arguments:\n",
    "    path -- path of weather data with data type\n",
    "    tarTimezone -- target timezone date is transformed into\n",
    "    dateFormat -- format of datetime\n",
    "    \"\"\"\n",
    "    w = pd.read_csv(path)\n",
    "    eastern = pytz.timezone(tarTimezone)\n",
    "    fmt = dateFormat\n",
    "    w[\"dt_iso\"] = w[\"dt_iso\"].apply(lambda x: pd.to_datetime(x[:-10], utc=True))\n",
    "    w[\"dt\"] = w[\"dt_iso\"].apply(lambda x: x.astimezone(eastern).strftime(fmt))\n",
    "    w[\"dt\"] = w[\"dt\"].apply(lambda x: pd.to_datetime(x))\n",
    "    w = w.set_index(\"dt\")\n",
    "    return w[[\"temp\", \"feels_like\", \"temp_min\", \"temp_max\", \"humidity\", \"wind_speed\", \n",
    "              \"rain_1h\", \"rain_3h\", \"snow_1h\", \"snow_3h\", \"weather_main\", \"weather_description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = loadWeatherData(\"taxi_data/weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322 duplicates found and removed.\n"
     ]
    }
   ],
   "source": [
    "w = prepData(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.to_csv(\"taxi_data/weather_prepared.csv\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
